# Streamlit Azure OpenAI チャットボットアプリケーション設計書

## 1. 全体システムアーキテクチャ

このアプリケーションは、StreamlitフロントエンドとカスタムLLM Agentを介してAzure OpenAI APIを使用するバックエンドで構成されるチャットボットアプリケーションです。ユーザーはローカルPCでアプリケーションを実行し、カスタムLLM Agentを通じてAzure OpenAI APIと会話を行います。

```
+-------------------+        +-------------------+        +-------------------+        +-------------------+
|                   |        |                   |        |                   |        |                   |
|  Streamlit UI     | <----> |  Python Backend   | <----> |  Custom LLM Agent | <----> |  Azure OpenAI API |
|  (フロントエンド)  |        |  (ロジック処理)    |        |  (Agent処理)      |        |  (LLMサービス)    |
|                   |        |                   |        |                   |        |                   |
+-------------------+        +-------------------+        +-------------------+        +-------------------+
```

## 2. 主要コンポーネントとその相互作用

### 2.1 フロントエンド (Streamlit)
- ユーザーインターフェース表示
- メッセージ入力フォーム
- チャット履歴表示
- ストリーミングレスポンス表示

### 2.2 バックエンド (Python)
- メッセージ履歴管理
- ストリーミングレスポンス処理
- エラーハンドリング
- LLM Agentとの通信

### 2.3 カスタムLLM Agent
- 独自のロジックによるメッセージ処理
- Azure OpenAI API通信処理
- 拡張可能なエージェントフレームワーク
- プロンプトエンジニアリングとコンテキスト管理
- ストリーミングレスポンス対応

### 2.4 外部サービス
- Azure OpenAI API: Azure上でホストされたOpenAIモデルへのアクセス

### 2.5 コンポーネント間の相互作用
1. ユーザーがStreamlit UIでメッセージを入力
2. Pythonバックエンドがメッセージを受け取り、会話履歴と共にカスタムLLM Agentに転送
3. カスタムLLM Agentが独自のロジックでメッセージを処理し、必要に応じてAzure OpenAI APIにリクエスト送信
4. Azure OpenAI APIからのレスポンスをLLM Agentが受信し、必要な後処理を実施
5. LLM Agentからのレスポンスをバックエンドがストリーミング形式で受信
6. ストリーミングレスポンスをリアルタイムでStreamlit UIに表示
7. 会話履歴を更新

## 3. 必要なライブラリと依存関係

### 3.1 主要ライブラリ
- **streamlit**: UIフレームワーク
- **openai**: OpenAI APIクライアント
- **python-dotenv**: 環境変数管理
- **pydantic**: データバリデーションとモデル定義
- **typing-extensions**: 高度な型ヒント

### 3.2 依存関係
```
streamlit>=1.32.0
openai>=1.12.0
python-dotenv>=1.0.0
pydantic>=2.0.0
typing-extensions>=4.5.0
```

## 4. StreamlitフロントエンドとAzure OpenAI API間のデータフロー

### 4.1 データフロー図
```
+----------------+     +----------------+     +----------------+     +----------------+
|                |     |                |     |                |     |                |
| ユーザー入力    | --> | メッセージ処理  | --> | LLM Agent     | --> | Azure OpenAI   |
| (Streamlit)    |     | (Python)       |     | 処理           |     | API呼出        |
|                |     |                |     | (Agent Logic)  |     | (HTTP Request) |
+----------------+     +----------------+     +----------------+     +----------------+
                                                                            |
                                                                            v
                                                                     +----------------+
                                                                     |                |
                                                                     | LLM Agent      |
                                                                     | レスポンス処理  |
                                                                     |                |
                                                                     +----------------+
                                                                            |
                                                                            v
                       +----------------+     +----------------+     +----------------+
                       |                |     |                |     |                |
                       | 会話履歴更新   | <-- | UI更新         | <-- | ストリーミング |
                       | (Python)       |     | (Streamlit)    |     | レスポンス処理  |
                       |                |     |                |     | (Python)       |
                       +----------------+     +----------------+     +----------------+
```

### 4.2 データ構造
- **メッセージ**: `{"role": str, "content": str}`
- **会話履歴**: `List[Dict[str, str]]`
- **ストリーミングレスポンス**: チャンク単位のテキスト
- **Agent設定**: `Dict[str, Any]` (Agentの動作を制御するパラメータ)
- **Agent状態**: `Dict[str, Any]` (Agentの内部状態を保持)

## 5. ユーザーインターフェースのレイアウトと機能

### 5.1 レイアウト
- ヘッダー: アプリケーションタイトル
- サイドバー: 設定パネル（Azure OpenAI設定入力など）
- メインエリア:
  - チャット履歴表示領域
  - メッセージ入力フォーム

### 5.2 機能
- **メッセージ送信**: テキスト入力とボタンによるメッセージ送信
- **チャット履歴表示**: ユーザーとAIのメッセージを視覚的に区別して表示
- **ストリーミング表示**: AIの応答をリアルタイムで表示
- **設定管理**: Azure OpenAI APIキー、エンドポイント、デプロイメント名、APIバージョンなどの設定
- **会話リセット**: 会話履歴をクリアする機能

## 6. エラーハンドリングアプローチ

### 6.1 想定されるエラー
- API接続エラー
- 認証エラー（無効なAPIキー）
- レート制限エラー
- モデル利用不可エラー
- ストリーミング中断エラー

### 6.2 エラーハンドリング戦略
- **try-except構造**: すべてのAPI呼び出しをtry-except文で囲む
- **ユーザーフレンドリーなエラーメッセージ**: 技術的詳細を隠し、ユーザーが理解できるメッセージを表示
- **リトライメカニズム**: 一時的なエラーに対する自動リトライ
- **フォールバック応答**: APIエラー時に代替メッセージを表示
- **ログ記録**: エラー情報をログに記録（デバッグ用）

## 7. 追加考慮事項

### 7.1 メッセージ履歴管理
- **セッション状態**: Streamlitのセッション状態を使用して会話履歴を保持
- **コンテキスト管理**: トークン数制限を考慮した会話履歴の管理
- **永続化オプション**: 会話履歴の保存と読み込み機能（オプション）

### 7.2 ストリーミング実装詳細
- **SSE (Server-Sent Events)**: Azure OpenAI APIのストリーミングレスポンスを処理
- **増分更新**: Streamlitの`empty()`コンテナを使用して応答を増分的に更新
- **タイプライターエフェクト**: 文字が徐々に表示される効果の実装

### 7.3 ユーザーエクスペリエンス設計
- **レスポンシブデザイン**: 異なる画面サイズに対応
- **視覚的フィードバック**: 処理中の状態を示すローディングインジケータ
- **メッセージスタイリング**: ユーザーとAIのメッセージを視覚的に区別
- **キーボードショートカット**: Enterキーでメッセージ送信など

### 7.4 ローカル環境セットアップ要件
- **Python環境**: Python 3.8以上
- **依存関係インストール**: pipを使用したライブラリインストール
- **環境変数**: `.env`ファイルを使用したAzure OpenAI設定の管理
- **実行コマンド**: `streamlit run app.py`

### 7.5 カスタムLLM Agent設計

#### 7.5.1 アーキテクチャ概要
カスタムLLM Agentは、抽象基底クラス（BaseAgent）と具体的な実装クラスから構成される階層構造を持ちます。この設計により、共通インターフェースを維持しながら、様々なユースケースに対応する柔軟な拡張が可能になります。

```
+----------------+
|                |
|   BaseAgent    |  <-- 抽象基底クラス（インターフェース定義）
|   (Abstract)   |
|                |
+-------^--------+
        |
        |
+-------+--------+--------+--------+
|                |        |        |
| AzureOpenAI    | Context| Tool   | ... その他の
| Agent          | Aware  | Using  |     実装
|                | Agent  | Agent  |
+----------------+--------+--------+
```

#### 7.5.2 主要ユースケース
1. **基本Q&A（AzureOpenAIAgent）**
   - Azure OpenAI APIを直接使用した基本的な質問応答
   - ストリーミングレスポンスのサポート
   - 会話履歴の管理

2. **コンテキスト対応（ContextAwareAgent）**
   - ドキュメントコンテキストを活用した情報提供
   - 関連情報の検索と統合
   - より詳細で正確な応答の生成

3. **ツール活用（ToolUsingAgent）**
   - 外部ツール/APIの呼び出し
   - 計算、データ検索、外部サービス連携
   - 複雑なタスクの実行支援

4. **マルチモーダル対応**
   - テキスト以外のメディア（画像、音声など）の処理
   - 複数モダリティの入出力サポート

5. **パーソナライズ対応**
   - ユーザー設定に基づく応答のカスタマイズ
   - 学習と適応による個人化

6. **ドメイン特化**
   - 特定分野（医療、金融、法律など）に特化した知識と応答
   - 専門用語や概念の理解

7. **推論エージェント**
   - 複雑な問題に対するステップバイステップの推論
   - 論理的思考プロセスの提示

8. **会話エージェント**
   - 複数ターンの会話コンテキスト維持
   - 自然な会話フローの実現

#### 7.5.3 クラス設計と責務

**BaseAgent（抽象基底クラス）**
- インターフェース定義
- 共通機能の実装
- 設定管理
- 状態管理

**具体的実装クラス**
- 特定ユースケースに対応する実装
- 基底クラスのインターフェースを継承
- 特化した機能の追加

#### 7.5.4 インターフェース設計原則
- **一貫性**: すべてのエージェントは同じインターフェースを実装
- **分離**: 内部実装の詳細はインターフェースから隠蔽
- **拡張性**: 新しいエージェントタイプの追加が容易
- **互換性**: Streamlitアプリケーションとの一貫した接続

#### 7.5.5 設定と状態管理
- **設定管理**: 環境変数とコンフィグファイルによるAgent設定
- **プラグイン機構**: 機能拡張のためのプラグインシステム
- **ステート管理**: 会話状態と文脈の管理
- **設定の動的更新**: 実行時の設定変更サポート

### 7.6 LLM Agent機能

#### 7.6.1 共通機能
- **プロンプトエンジニアリング**: 効果的なプロンプト設計と管理
- **コンテキスト管理**: 会話履歴の最適化と管理
- **ストリーミング対応**: リアルタイムレスポンス処理
- **エラーハンドリング**: 例外処理と回復メカニズム

#### 7.6.2 拡張機能
- **ツール統合**: 外部ツールやAPIとの連携機能
- **コンテキスト検索**: 関連ドキュメントの検索と活用
- **マルチモーダル処理**: 複数の入出力モダリティ対応
- **フォールバックメカニズム**: エラー時の代替応答生成

#### 7.6.3 インターフェース仕様
- **process_message()**: ストリーミングレスポンス生成（Generator）
- **get_response()**: 非ストリーミングレスポンス生成
- **initialize()**: エージェント初期化
- **reset()**: 状態リセット
- **get_capabilities()**: 機能一覧取得
- **update_config()**: 設定更新

## 8. 実装計画

### 8.1 フェーズ1: 基本機能実装
- プロジェクト構造セットアップ
- 基本的なStreamlit UI実装
- OpenAI API連携（非ストリーミング）
- 会話履歴管理

### 8.2 フェーズ2: ストリーミング機能実装
- ストリーミングレスポンス処理
- UIのリアルタイム更新
- エラーハンドリング

### 8.3 フェーズ3: カスタムLLM Agent実装
- Agent基本構造の設計と実装
- インターフェース定義
- Azure OpenAI APIとの連携
- ストリーミング対応
- プロンプトエンジニアリング

### 8.4 フェーズ4: UI/UX改善
- スタイリングとレイアウト最適化
- レスポンシブデザイン
- ユーザビリティ向上
- Agent設定UIの追加

### 8.5 フェーズ5: 拡張機能実装
- 設定管理
- 会話履歴の保存/読み込み
- Agentプラグイン機構
- ツール統合
- その他の拡張機能
