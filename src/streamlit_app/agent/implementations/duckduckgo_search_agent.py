import time
from typing import Any, Dict, Generator, List, Optional

from duckduckgo_search import DDGS
from openai import AzureOpenAI
from pydantic import BaseModel, Field

from ..base.base_agent import BaseAgent


class SearchDecision(BaseModel):
    """æ¤œç´¢ã®å¿…è¦æ€§ã‚’åˆ¤æ–­ã™ã‚‹ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«"""
    should_search: bool = Field(description="æ¤œç´¢ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’ç¤ºã™ãƒ–ãƒ¼ãƒ«å€¤")
    reason: str = Field(description="åˆ¤æ–­ã®ç†ç”±")


class SearchQuery(BaseModel):
    """æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«"""
    query: str = Field(description="ç”Ÿæˆã•ã‚ŒãŸæ¤œç´¢ã‚¯ã‚¨ãƒª")
    keywords: list[str] = Field(description="æŠ½å‡ºã•ã‚ŒãŸä¸»è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", default_factory=list)


class QueryRefinement(BaseModel):
    """æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«"""
    should_refine: bool = Field(description="ã‚¯ã‚¨ãƒªã‚’æœ€é©åŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã©ã†ã‹")
    refined_query: str = Field(description="æœ€é©åŒ–ã•ã‚ŒãŸã‚¯ã‚¨ãƒªï¼ˆæœ€é©åŒ–ãŒä¸è¦ãªå ´åˆã¯ç©ºæ–‡å­—åˆ—ï¼‰")
    reason: str = Field(description="æœ€é©åŒ–ã®ç†ç”±ã¾ãŸã¯ä¸è¦ã¨åˆ¤æ–­ã—ãŸç†ç”±")


class DateExtraction(BaseModel):
    """æ—¥ä»˜æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«"""
    date_found: bool = Field(description="æ—¥ä»˜ãŒè¦‹ã¤ã‹ã£ãŸã‹ã©ã†ã‹")
    date: str = Field(description="æŠ½å‡ºã•ã‚ŒãŸæ—¥ä»˜æƒ…å ±ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆã¯ç©ºæ–‡å­—åˆ—ï¼‰")
    format: str = Field(description="æ—¥ä»˜ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆä¾‹ï¼šYYYY/MM/DDï¼‰", default="")


class SourceClassification(BaseModel):
    """æƒ…å ±ã‚½ãƒ¼ã‚¹ã‚’åˆ†é¡ã™ã‚‹ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«"""
    source_type: str = Field(description="ã€Œä¸€æ¬¡æƒ…å ±ã€ã€ã€ŒäºŒæ¬¡æƒ…å ±ã€ã€ã¾ãŸã¯ã€Œä¸æ˜ã€")
    confidence: float = Field(description="åˆ†é¡ã®ç¢ºä¿¡åº¦ï¼ˆ0.0-1.0ï¼‰", ge=0.0, le=1.0)
    reason: str = Field(description="åˆ†é¡ã®ç†ç”±")


class DuckDuckGoSearchAgent(BaseAgent):
    """
    An implementation of BaseAgent that uses DuckDuckGo search to enhance responses.
    This agent can search for external information to provide more accurate and up-to-date responses.
    """

    def initialize(self) -> None:
        """
        Initialize the Azure OpenAI client and DuckDuckGo search.
        """
        self.client = None
        if all(k in self.config for k in ["api_key", "api_version", "azure_endpoint"]):
            self.client = AzureOpenAI(
                api_key=self.config["api_key"],
                api_version=self.config["api_version"],
                azure_endpoint=self.config["azure_endpoint"],
            )

        if "deployment_name" not in self.config:
            self.config["deployment_name"] = "gpt-35-turbo"

        if "system_message" not in self.config:
            self.config[
                "system_message"
            ] = """ã‚ãªãŸã¯å¤–éƒ¨æƒ…å ±æ¤œç´¢æ©Ÿèƒ½ã‚’æŒã¤å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€å¿…è¦ã«å¿œã˜ã¦DuckDuckGoã§æ¤œç´¢ã‚’è¡Œã„ã€æœ€æ–°ã‹ã¤æ­£ç¢ºãªæƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚

æƒ…å ±ã®ä¿¡é ¼æ€§ã‚’è©•ä¾¡ã™ã‚‹éš›ã¯ã€ä»¥ä¸‹ã®ç‚¹ã«æ³¨æ„ã—ã¦ãã ã•ã„ï¼š
1. ä¸€æ¬¡æƒ…å ±ï¼ˆå…¬å¼ç™ºè¡¨ã€åŸè‘—è«–æ–‡ãªã©ï¼‰ã¯äºŒæ¬¡æƒ…å ±ã‚ˆã‚Šã‚‚ä¿¡é ¼æ€§ãŒé«˜ã„å‚¾å‘ãŒã‚ã‚Šã¾ã™
2. æƒ…å ±ã®æ–°ã—ã•ï¼ˆå…¬é–‹æ—¥æ™‚ï¼‰ã‚’è€ƒæ…®ã—ã€æœ€æ–°ã®æƒ…å ±ã‚’å„ªå…ˆã—ã¦ãã ã•ã„
3. è¤‡æ•°ã®æƒ…å ±æºãŒä¸€è‡´ã™ã‚‹æƒ…å ±ã¯ã‚ˆã‚Šä¿¡é ¼ã§ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™

å›ç­”ã§ã¯ã€ä½¿ç”¨ã—ãŸæƒ…å ±ã®ä¿¡é ¼æ€§ã«ã¤ã„ã¦è¨€åŠã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæƒ…å ±ã®è³ªã‚’åˆ¤æ–­ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚
"""

        if "search_enabled" not in self.config:
            self.config["search_enabled"] = True

        if "max_search_results" not in self.config:
            self.config["max_search_results"] = 3

        if "search_region" not in self.config:
            self.config["search_region"] = "jp-ja"

        if "news_search" not in self.config:
            self.config["news_search"] = True

        if "max_query_refinements" not in self.config:
            self.config["max_query_refinements"] = 1

        self.ddgs = DDGS()
        self.state["last_search_query"] = None
        self.state["last_search_results"] = None
        self.state["refined_query"] = None

    def _ask_llm(self, prompt: str, temperature: float = 0.0) -> str:
        """
        Azure OpenAI APIã‚’ä½¿ç”¨ã—ã¦å˜ä¸€ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹å›ç­”ã‚’å–å¾—ã—ã¾ã™ã€‚

        Args:
            prompt: è³ªå•ã‚„ã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            temperature: ç”Ÿæˆã®å¤šæ§˜æ€§ï¼ˆ0.0ã¯æ±ºå®šè«–çš„ã€1.0ã¯å‰µé€ çš„ï¼‰

        Returns:
            LLMã‹ã‚‰ã®å›ç­”ãƒ†ã‚­ã‚¹ãƒˆ
        """
        if not self.client:
            raise ValueError(
                "Azure OpenAI client is not initialized. Please check your configuration."
            )

        try:
            messages = [{"role": "user", "content": prompt}]
            response = self.client.chat.completions.create(
                model=self.config["deployment_name"],
                messages=messages,
                temperature=temperature,
                stream=False,
            )

            return response.choices[0].message.content
        except Exception as e:
            print(f"Error calling Azure OpenAI API: {str(e)}")
            return ""
            
    def _ask_llm_with_structured_output(self, prompt: str, json_schema: dict, temperature: float = 0.0) -> dict:
        """
        Azure OpenAI APIã‚’ä½¿ç”¨ã—ã¦æ§‹é€ åŒ–å‡ºåŠ›ã‚’è¿”ã™ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹å›ç­”ã‚’å–å¾—ã—ã¾ã™ã€‚
        
        Args:
            prompt: è³ªå•ã‚„ã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            json_schema: è¿”ã•ã‚Œã‚‹æ§‹é€ åŒ–JSONã®ã‚¹ã‚­ãƒ¼ãƒ
            temperature: ç”Ÿæˆã®å¤šæ§˜æ€§ï¼ˆ0.0ã¯æ±ºå®šè«–çš„ã€1.0ã¯å‰µé€ çš„ï¼‰
            
        Returns:
            æ§‹é€ åŒ–ã•ã‚ŒãŸJSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆè¾æ›¸å½¢å¼ï¼‰
        """
        if not self.client:
            raise ValueError(
                "Azure OpenAI client is not initialized. Please check your configuration."
            )
            
        try:
            messages = [{"role": "user", "content": prompt}]
            response = self.client.chat.completions.create(
                model=self.config["deployment_name"],
                messages=messages,
                temperature=temperature,
                response_format={"type": "json_object", "schema": json_schema},
                stream=False,
            )
            
            import json
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            print(f"Error calling Azure OpenAI API with structured output: {str(e)}")
            return {}

    def should_search(self, message: str) -> bool:
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¯¾ã—ã¦æ¤œç´¢ã‚’è¡Œã†ã¹ãã‹ã©ã†ã‹ã‚’åˆ¤æ–­ã—ã¾ã™ã€‚

        Args:
            message: åˆ†æã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

        Returns:
            æ¤œç´¢ã‚’è¡Œã†ã¹ãå ´åˆã¯Trueã€ãã†ã§ãªã„å ´åˆã¯False
        """
        if not self.config.get("search_enabled", True):
            return False

        if message.strip().lower().startswith(("æ¤œç´¢:", "search:")):
            return True

        prompt = f"""
        ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’åˆ†æã—ã€å¤–éƒ¨æƒ…å ±ã®æ¤œç´¢ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤æ–­ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
        
        ä»¥ä¸‹ã®ã‚ˆã†ãªå ´åˆã€å¤–éƒ¨æ¤œç´¢ãŒå¿…è¦ã¨åˆ¤æ–­ã—ã¦ãã ã•ã„ï¼š
        - æœ€æ–°ã®æƒ…å ±ã‚„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ±‚ã‚ã¦ã„ã‚‹è³ªå•
        - ç‰¹å®šã®äº‹å®Ÿã‚„çµ±è¨ˆã«é–¢ã™ã‚‹è³ªå•
        - ç‰¹å®šã®å ´æ‰€ã€äººç‰©ã€ã‚¤ãƒ™ãƒ³ãƒˆãªã©ã«é–¢ã™ã‚‹å…·ä½“çš„ãªæƒ…å ±ã‚’æ±‚ã‚ã‚‹è³ªå•
        - ã€Œèª¿ã¹ã¦ã€ã€Œæ•™ãˆã¦ã€ãªã©ã®æ˜ç¤ºçš„ãªæƒ…å ±è¦æ±‚ã‚’å«ã‚€è³ªå•
        
        ä»¥ä¸‹ã®ã‚ˆã†ãªå ´åˆã¯å¤–éƒ¨æ¤œç´¢ãŒä¸è¦ã§ã™ï¼š
        - ä¸€èˆ¬çš„ãªæ¦‚å¿µã‚„å®šç¾©ã«é–¢ã™ã‚‹è³ªå•
        - å€‹äººçš„ãªæ„è¦‹ã‚„ææ¡ˆã‚’æ±‚ã‚ã‚‹è³ªå•
        - ä¼šè©±ã®ç¶™ç¶šã‚„æŒ¨æ‹¶
        
        ã€Œ{message}ã€
        
        ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯å¤–éƒ¨æƒ…å ±ã®æ¤œç´¢ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤æ–­ã—ã€ç†ç”±ã‚‚èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
        """

        schema = SearchDecision.schema()
        result = self._ask_llm_with_structured_output(prompt, schema)
        
        if not result:
            return False
            
        return result.get("should_search", False)

    def generate_search_query(self, message: str) -> str:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¾ã™ã€‚

        Args:
            message: ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

        Returns:
            æ¤œç´¢ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—
        """
        if message.strip().lower().startswith(("æ¤œç´¢:", "search:")):
            return message.split(":", 1)[1].strip()

        prompt = f"""
        ã‚ãªãŸã¯æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®å°‚é–€å®¶ã§ã€åŠ¹æœçš„ãªæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ä½œæˆã™ã‚‹ã‚¹ã‚­ãƒ«ã‚’æŒã£ã¦ã„ã¾ã™ã€‚
        
        ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åˆ†æã—ã€æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„æƒ…å ±ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã®æœ€é©ãªæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        
        - ç°¡æ½”ã§å…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹
        - ä¸è¦ãªè¨€è‘‰ï¼ˆã€Œã«ã¤ã„ã¦æ•™ãˆã¦ã€ãªã©ï¼‰ã¯çœç•¥ã™ã‚‹
        - é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã ã‘ã‚’å«ã‚ã‚‹
        - æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã§æœ€è‰¯ã®çµæœã‚’å¾—ã‚‰ã‚Œã‚‹ã‚ˆã†ã«æœ€é©åŒ–ã™ã‚‹
        - æ—¥æœ¬èªã®ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã™ã‚‹
        
        ã€Œ{message}ã€
        
        """

        query = self._ask_llm(prompt).strip()

        if len(query) > 100:
            query = query[:100]

        return query.strip()

    def perform_search(self, query: str) -> List[Dict[str, str]]:
        """
        Perform a DuckDuckGo search with the given query.

        Args:
            query: The search query.

        Returns:
            A list of search results.
        """
        try:
            max_results = self.config.get("max_search_results", 3)
            region = self.config.get("search_region", "jp-ja")
            use_news = self.config.get("news_search", True)

            results = []

            if use_news:
                news_results = list(
                    self.ddgs.news(
                        query,
                        region=region,
                        max_results=max(1, max_results // 2),  # æ¤œç´¢çµæœã®åŠåˆ†ã‚’ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‹ã‚‰
                    )
                )
                results.extend(news_results)

            text_results = list(
                self.ddgs.text(
                    query,
                    region=region,
                    max_results=max_results - len(results),  # æ®‹ã‚Šã®æ ã‚’é€šå¸¸æ¤œç´¢ã§åŸ‹ã‚ã‚‹
                )
            )
            results.extend(text_results)

            formatted_results = []
            for result in results:
                date_info = self.extract_date_info(result)
                source_type = self.classify_information_source(result)

                formatted_results.append(
                    {
                        "title": result.get("title", ""),
                        "body": result.get("body", ""),
                        "href": result.get("href", ""),
                        "date": date_info,
                        "source_type": source_type,
                    }
                )

            self.state["last_search_query"] = query
            self.state["last_search_results"] = formatted_results

            return formatted_results
        except Exception as e:
            print(f"Search error: {str(e)}")
            return []

    def refine_search_query(
        self, original_query: str, results: List[Dict[str, str]]
    ) -> Optional[str]:
        """
        åˆæœŸæ¤œç´¢çµæœã«åŸºã¥ã„ã¦æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚

        Args:
            original_query: å…ƒã®æ¤œç´¢ã‚¯ã‚¨ãƒª
            results: åˆæœŸæ¤œç´¢çµæœ

        Returns:
            æœ€é©åŒ–ãŒå¿…è¦ãªå ´åˆã¯æœ€é©åŒ–ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã€ãã†ã§ãªã„å ´åˆã¯None
        """
        if not results or len(results) >= self.config.get("max_search_results", 3):
            return None  # ååˆ†ãªçµæœãŒã‚ã‚‹å ´åˆã¯æœ€é©åŒ–ä¸è¦

        results_summary = "\n".join(
            [
                f"ã‚¿ã‚¤ãƒˆãƒ«: {result.get('title', '')}\nå†…å®¹: {result.get('body', '')[:100]}..."
                for result in results
            ]
        )

        prompt = f"""
        ã‚ãªãŸã¯æ¤œç´¢ã‚¯ã‚¨ãƒªæœ€é©åŒ–ã®å°‚é–€å®¶ã§ã™ã€‚æ¤œç´¢çµæœãŒå°‘ãªã„å ´åˆã«ã€ã‚ˆã‚Šè‰¯ã„çµæœã‚’å¾—ã‚‹ãŸã‚ã«ã‚¯ã‚¨ãƒªã‚’æ”¹å–„ã—ã¾ã™ã€‚
        
        å…ƒã®æ¤œç´¢ã‚¯ã‚¨ãƒª: ã€Œ{original_query}ã€
        æ¤œç´¢çµæœæ•°: {len(results)}ä»¶ï¼ˆæœ€å¤§{self.config.get("max_search_results", 3)}ä»¶ä¸­ï¼‰
        
        {results_summary}
        
        ã‚ˆã‚Šå¤šãã®é–¢é€£æƒ…å ±ã‚’å¾—ã‚‹ãŸã‚ã«ã€æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ”¹å–„ã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®æ–¹æ³•ã‚’é©ç”¨ã§ãã¾ã™ï¼š
        - ã‚ˆã‚Šä¸€èˆ¬çš„ãªç”¨èªã‚’ä½¿ç”¨ã™ã‚‹
        - åˆ¥ã®è¨€ã„å›ã—ã‚’è©¦ã™
        - é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ ã™ã‚‹
        - åˆ¶é™çš„ã™ãã‚‹ä¿®é£¾èªã‚’å‰Šé™¤ã™ã‚‹
        
        ã§ãã‚‹ã ã‘ç°¡æ½”ãªã‚¯ã‚¨ãƒªã‚’1ã¤ã ã‘ææ¡ˆã—ã¦ãã ã•ã„ã€‚ã‚¯ã‚¨ãƒªã‚’å¤‰æ›´ã™ã‚‹å¿…è¦ãŒãªã„å ´åˆã¯ã€Œå¤‰æ›´ä¸è¦ã€ã¨å›ç­”ã—ã¦ãã ã•ã„ã€‚
        
        """

        refined_query = self._ask_llm(prompt).strip()

        if (
            refined_query
            and "å¤‰æ›´ä¸è¦" not in refined_query
            and refined_query != original_query
        ):
            return refined_query

        return None

    def extract_date_info(self, result: Dict[str, str]) -> Optional[str]:
        """
        æ¤œç´¢çµæœã‹ã‚‰å…¬é–‹æ—¥æƒ…å ±ã‚’æŠ½å‡ºã—ã¾ã™ã€‚

        Args:
            result: æ—¥ä»˜ã‚’æŠ½å‡ºã™ã‚‹æ¤œç´¢çµæœ

        Returns:
            æ—¥ä»˜ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã¯ãã®æ–‡å­—åˆ—è¡¨ç¾ã€è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆã¯None
        """
        if "published" in result:
            return result.get("published", None)

        title = result.get("title", "")
        body = result.get("body", "")

        prompt = f"""
        ã‚ãªãŸã¯ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ—¥ä»˜æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
        
        ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å…¬é–‹æ—¥ã¾ãŸã¯æœ€å¾Œã®æ›´æ–°æ—¥ã¨æ€ã‚ã‚Œã‚‹æ—¥ä»˜æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
        
        ã‚¿ã‚¤ãƒˆãƒ«: {title}
        æœ¬æ–‡: {body}
        
        - æ—¥ä»˜ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€Œè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€ã¨å›ç­”ã—ã¦ãã ã•ã„
        - è¤‡æ•°ã®æ—¥ä»˜ãŒã‚ã‚‹å ´åˆã¯ã€æœ€ã‚‚æœ€è¿‘ã®ã‚‚ã®ã‚’é¸æŠã—ã¦ãã ã•ã„
        - æ—¥ä»˜ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯ãã®ã¾ã¾æŠ½å‡ºã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼š2023å¹´3æœˆ15æ—¥ã€2023/03/15ãªã©ï¼‰
        
        """

        date_info = self._ask_llm(prompt).strip()

        if "è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“" in date_info or not date_info:
            return None

        return date_info

    def classify_information_source(self, result: Dict[str, str]) -> str:
        """
        æ¤œç´¢çµæœã‚’ä¸€æ¬¡æƒ…å ±ã¾ãŸã¯äºŒæ¬¡æƒ…å ±ã¨ã—ã¦åˆ†é¡ã—ã¾ã™ã€‚

        Args:
            result: åˆ†é¡ã™ã‚‹æ¤œç´¢çµæœ

        Returns:
            "ä¸€æ¬¡æƒ…å ±"ã€"äºŒæ¬¡æƒ…å ±"ã€ã¾ãŸã¯"ä¸æ˜"ã¨ã—ã¦ã®åˆ†é¡
        """
        href = result.get("href", "")
        title = result.get("title", "")
        body = result.get("body", "")

        prompt = f"""
        ã‚ãªãŸã¯æƒ…å ±ã‚½ãƒ¼ã‚¹ã®åˆ†é¡å°‚é–€å®¶ã§ã™ã€‚æƒ…å ±ã‚’ä¸€æ¬¡æƒ…å ±ï¼ˆç›´æ¥ã®æƒ…å ±æºï¼‰ã¨äºŒæ¬¡æƒ…å ±ï¼ˆé–“æ¥çš„ãªæƒ…å ±æºï¼‰ã«åˆ†é¡ã—ã¾ã™ã€‚
        
        ä¸€æ¬¡æƒ…å ±ï¼ˆãƒ—ãƒ©ã‚¤ãƒãƒªãƒ¼ã‚½ãƒ¼ã‚¹ï¼‰:
        - æ”¿åºœã‚„å…¬å¼æ©Ÿé–¢ã‹ã‚‰ã®ç›´æ¥ã®ç™ºè¡¨
        - ä¼æ¥­ã‚„çµ„ç¹”ã®å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã‚„ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹
        - ç›´æ¥ã®è¨¼è¨€ã‚„ä¸€æ¬¡è³‡æ–™
        - åŸè‘—è«–æ–‡ã‚„ç ”ç©¶å ±å‘Šæ›¸
        
        äºŒæ¬¡æƒ…å ±ï¼ˆã‚»ã‚«ãƒ³ãƒ€ãƒªãƒ¼ã‚½ãƒ¼ã‚¹ï¼‰:
        - ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚µã‚¤ãƒˆã‚„å ±é“æ©Ÿé–¢ã«ã‚ˆã‚‹å ±é“
        - ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚„ãƒ¬ãƒ“ãƒ¥ãƒ¼
        - è§£èª¬è¨˜äº‹ã‚„åˆ†æ
        - ã¾ã¨ã‚ã‚µã‚¤ãƒˆã‚„æƒ…å ±ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        
        URL: {href}
        ã‚¿ã‚¤ãƒˆãƒ«: {title}
        å†…å®¹: {body[:300]}...
        
        ä¸Šè¨˜ã®æƒ…å ±ã‚½ãƒ¼ã‚¹ã‚’åˆ†æã—ã€ã€Œä¸€æ¬¡æƒ…å ±ã€ã€ã€ŒäºŒæ¬¡æƒ…å ±ã€ã€ã¾ãŸã¯ã€Œä¸æ˜ã€ã«åˆ†é¡ã—ã¦ãã ã•ã„ã€‚
        ç†ç”±ã‚‚ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
        
        """

        classification_result = self._ask_llm(prompt)

        if "ä¸€æ¬¡æƒ…å ±" in classification_result:
            return "ä¸€æ¬¡æƒ…å ±"
        elif "äºŒæ¬¡æƒ…å ±" in classification_result:
            return "äºŒæ¬¡æƒ…å ±"
        else:
            return "ä¸æ˜"

    def format_search_results(self, results: List[Dict[str, str]]) -> str:
        """
        Format search results as a string.

        Args:
            results: The search results to format.

        Returns:
            Formatted search results string.
        """
        if not results:
            return "æ¤œç´¢çµæœã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

        formatted = "æ¤œç´¢çµæœ:\n\n"
        for i, result in enumerate(results, 1):
            formatted += f"{i}. {result['title']}\n"
            formatted += f"   {result['body']}\n"

            if result.get("date"):
                formatted += f"   ğŸ“… å…¬é–‹æ—¥: {result['date']}\n"

            source_type = result.get("source_type", "ä¸æ˜")
            formatted += f"   ğŸ“Š æƒ…å ±ã®ç¨®é¡: {source_type}\n"

            formatted += f"   ğŸ”— å‡ºå…¸: {result['href']}\n\n"

        return formatted

    def process_message(
        self, message: str, context: Optional[List[Dict[str, str]]] = None
    ) -> Generator[str, None, Dict[str, Any]]:
        """
        Process a user message and generate a streaming response with search integration.

        Args:
            message: The user message to process.
            context: Optional conversation history or context.

        Returns:
            A generator that yields response chunks for streaming and finally returns
            a dictionary containing the complete response and any additional metadata.
        """
        if not self.client:
            raise ValueError(
                "Azure OpenAI client is not initialized. Please check your configuration."
            )

        search_results = []
        search_info = ""

        if self.should_search(message):
            query = self.generate_search_query(message)

            yield f"ğŸ” ã€Œ{query}ã€ã‚’æ¤œç´¢ä¸­...\n\n"
            search_results = self.perform_search(query)

            if (
                len(search_results) < 2
                and self.config.get("max_query_refinements", 1) > 0
            ):
                refined_query = self.refine_search_query(query, search_results)
                if refined_query and refined_query != query:
                    yield f"ğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ã€Œ{refined_query}ã€ã«æ”¹å–„ã—ã¦å†æ¤œç´¢ä¸­...\n\n"
                    self.state["refined_query"] = refined_query
                    search_results = self.perform_search(refined_query)

            if search_results:
                search_info = self.format_search_results(search_results)
                yield f"{search_info}\n\nå›ç­”ã‚’ç”Ÿæˆä¸­...\n\n"

        messages = []

        system_message = self.config.get(
            "system_message", "ã‚ãªãŸã¯å¤–éƒ¨æƒ…å ±æ¤œç´¢æ©Ÿèƒ½ã‚’æŒã¤å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        )

        if search_results:
            system_message += (
                f"\n\nä»¥ä¸‹ã®æ¤œç´¢çµæœã‚’å‚è€ƒã«ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚æ¤œç´¢çµæœãŒè³ªå•ã«é–¢é€£ã—ãªã„å ´åˆã¯ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚\n\n{search_info}"
            )

        messages.append({"role": "system", "content": system_message})

        if context:
            messages.extend(context)

        messages.append({"role": "user", "content": message})

        try:
            stream = self.client.chat.completions.create(
                model=self.config["deployment_name"],
                messages=messages,
                stream=True,
            )

            full_response = ""

            for chunk in stream:
                if (
                    chunk.choices
                    and len(chunk.choices) > 0
                    and chunk.choices[0].delta
                    and chunk.choices[0].delta.content is not None
                ):
                    content = chunk.choices[0].delta.content
                    full_response += content
                    yield content

            return {
                "response": full_response,
                "model": self.config["deployment_name"],
                "timestamp": time.time(),
                "search_performed": bool(search_results),
                "search_query": self.state.get("last_search_query"),
                "search_results": self.state.get("last_search_results"),
            }

        except Exception as e:
            error_message = f"Error calling Azure OpenAI API: {str(e)}"
            yield error_message
            return {
                "response": error_message,
                "error": str(e),
                "timestamp": time.time(),
            }

    def get_response(
        self, message: str, context: Optional[List[Dict[str, str]]] = None
    ) -> Dict[str, Any]:
        """
        Process a user message and return a complete response (non-streaming) with search integration.

        Args:
            message: The user message to process.
            context: Optional conversation history or context.

        Returns:
            A dictionary containing the complete response and any additional metadata.
        """
        if not self.client:
            raise ValueError(
                "Azure OpenAI client is not initialized. Please check your configuration."
            )

        search_results = []
        search_info = ""

        if self.should_search(message):
            query = self.generate_search_query(message)

            search_results = self.perform_search(query)

            if search_results:
                search_info = self.format_search_results(search_results)

        messages = []

        system_message = self.config.get(
            "system_message", "ã‚ãªãŸã¯å¤–éƒ¨æƒ…å ±æ¤œç´¢æ©Ÿèƒ½ã‚’æŒã¤å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        )

        if search_results:
            system_message += (
                f"\n\nä»¥ä¸‹ã®æ¤œç´¢çµæœã‚’å‚è€ƒã«ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚æ¤œç´¢çµæœãŒè³ªå•ã«é–¢é€£ã—ãªã„å ´åˆã¯ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚\n\n{search_info}"
            )

        messages.append({"role": "system", "content": system_message})

        if context:
            messages.extend(context)

        messages.append({"role": "user", "content": message})

        try:
            response = self.client.chat.completions.create(
                model=self.config["deployment_name"],
                messages=messages,
                stream=False,
            )

            content = response.choices[0].message.content

            return {
                "response": content,
                "model": self.config["deployment_name"],
                "timestamp": time.time(),
                "finish_reason": response.choices[0].finish_reason,
                "search_performed": bool(search_results),
                "search_query": self.state.get("last_search_query"),
                "search_results": self.state.get("last_search_results"),
                "usage": {
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "total_tokens": response.usage.total_tokens,
                },
            }

        except Exception as e:
            error_message = f"Error calling Azure OpenAI API: {str(e)}"
            return {
                "response": error_message,
                "error": str(e),
                "timestamp": time.time(),
            }

    def get_capabilities(self) -> List[str]:
        """
        Get a list of the agent's capabilities.

        Returns:
            A list of capability strings.
        """
        return [
            "text_generation",
            "streaming_response",
            "conversation_context",
            "external_search",
            "real_time_information",
        ]
